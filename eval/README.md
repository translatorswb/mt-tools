| Metric | Description                                                                                                                                                                                            | Implementation                                                                                                                    |
|--------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------|
| BLEU   | (Bilingual Evaluation Understudy)  The proportion of word n-grams in the MT output that are also found in one or more references                                                                                                               | moses, [nltk](https://www.nltk.org/_modules/nltk/translate/bleu_score.html)                                                                                                                       |
| ChrF   | F-score of character n-grams of maximal length 6                                                                                                                                                       | [nltk](https://www.nltk.org/_modules/nltk/translate/chrf_score.html)                                                              |
| NIST   | Based on the BLEU metric but the rarer that n-gram is, the more weight it will be given.                                                                                                             | [nltk](https://www.nltk.org/_modules/nltk/translate/nist_score.html)                                                              |
| METEOR | Harmonic mean of unigram precision and recall, with recall weighted higher than precision. Language specific metrics are available for a bunch of languages. But it is possible to train for new ones. | [java](https://www.cs.cmu.edu/~alavie/METEOR/README.html), [nltk](https://www.nltk.org/_modules/nltk/translate/meteor_score.html) |
| TER    | Translation Edit Rate                                                                                                                                                                                  | [pyter](https://github.com/aflc/pyter)                                                                                            |
| ROUGE  | (Recall-Oriented Understudy for Gisting Evaluation) Lexical recall among n-grams up to length 4. Also allows skip-grams.                                                                               | [python](https://github.com/pltrdy/rouge)                                                                                         |
